---
title: "FIE5-2-IOS-4-Devoir-2"
author: "Adrien Wartelle"
date: "2026-01-11"
output: html_notebook # html_document
editor_options: 
  markdown: 
    wrap: 72
---

# Etude de cas sur l’analyse et la mesure de performance des Flux de Patients

## Introduction

Ce travail porte sur l'analyse des flux de patients sur un plateau
mutualisé de consultations externes d'un hôpital. L'objectif est de
réaliser un diagnostic objectif de la performance organisationnelle du
service d'urologie en s'appuyant sur les méthodes et outils d'analyse de
flux vus précédemment ainsi que sur le langage R à travers
l’environnement de RStudio. La figure ci-dessous illustre les principaux
flux ainsi que le Plan du plateau de consultations (voir fichiers
PlanConsultations.pdf et ZoomURO.pdf consultables à partir
<http://bit.ly/PlansCHUTlse>)

<!--<img src="illustrations/PlanUro.png" alt="Plan du plateau de consultations" width="600"/>-->

![Plan du plateau de
consultations](illustrations/PlanUro.png "Plan du plateau de consultations")
Afin de collecter des données sur les parcours suivis, les patients qui
se sont présentés le 12/11/2015 ont été équipés d’une étiquette
électronique (type RFID) qui a permis de tracer leurs parcours dans le
plateau de consultation. Les données collectées ont été fusionnées avec
les données des outils de gestion des dossiers administratifs et
médicaux utilisés par les personnels. L'ensemble est disponible sous la
forme d’un fichier log, illustré par le tableau suivant (voir annexe
LogPatientUROseul_12112015.xlsx consultable à partir
<http://bit.ly/logPatients>).

<!--<img src="illustrations/TableauLogPatients.png" alt="Vue du tableau de données de log patient" width="600"/>-->

![*Vue du tableau de données de log
patient*](illustrations/TableauLogPatients.png "Vue du tableau de données de log patient")

Les différentes de ce tableau de données sont :

-   *ID* (Col A) : Identifiant du patient
-   *Timestamp start* (Col B) : horodatage entrée de zone ou salle
-   *Timestamp end* (Col C) : horodatage sortie de zone ou salle
-   *Activity_MACRO* (Col D) : Activité suivie et indice salle (i)
-   *Activity_DETAILS* (Col E) : Type d'activité
-   *Ress.Humaines* (Col F) : Ressources humaines administratives ou
    soignantes intervenant dans l'activité
-   *distance parcourues* (Col G) : Distance parcourue cumulée
-   *début/fin opX* (Col H à O) : horodatage début/fin de chaque
    opération de prise en charge par une ressources administrative ou
    soignante (maxi 4 opérations par activité).

## **Devoir 2 - Travail demandé** : Modélisation *data-driven* du service d'urologie

Ce travail est à rendre pour le **11/02/2026** (avant le cours) au
format Rmd ou R (+pdf si besoin) avec pour titre
"NOM_Prenom_FIE5-2-IOS-4-Devoir-2.\*"

```{r include=FALSE}
library(tidyverse)
library(data.table)
library(comprehenr)
library(MASS)
```

Ce deuxième devoir se place en suite directe du premier et vous propose
un premier type de modélisation *data-driven* (et top down),
c'est-à-dire basé sur les travaux de Whitt & Zhang (2017) *A data-driven
model of an emergency department*.

### Question 1) Loi de Little (/3)

Pour rappel, la loi de Little est une loi fondamentale qui, dans un
cadre asymptotique, lie le niveau d'occupation moyen au temps d'attente
moyen par le taux d'arrivée moyen selon la formule donnée ci-dessous :
$$ L = \lambda W $$ - $L$ : Niveau d'occupation moyen (asymptotique) -
$\lambda$ : Taux d'arrivée moyen (asymptotique) - $W$ : Temps d'attente
moyen (asymptotique)

Cette loi s'applique quel que soit le système ou modèle considéré à
partir du moment où $L<+\infty$, $W<+\infty$ et $\lambda<+\infty$
(Little JDC, Graves SC. *Little’s law*. In: International series in
operations research and management science. 2008: 81–100.)

Pour cette première question, il vous est demandé de vérifier que cette
loi "s'applique" bien sur notre service d'urologie durant la période de
**8h à 18h** de la journée du 12/11/2015.

Réponse :

```         
Attention : utiliser bien les **arrivées initiales** des patients et pas les arrivées intermédiaires après une transition
```

-   Calcul le niveau d'occupation moyen :

    Rappel et conseil : $L = \frac{1}{\int dt} \int l(t)dt$ avec
    $l(t) = A(t) - D(t)$, vous pouvez calculer en décomposant la période
    en zone $i$ de même niveau d'occupation et en calculant
    $L[8h;18h] = \frac{1}{\sum_i t_i} \sum_i l_i t_i$ avec $t_i$ la
    durée de la zone $i$

```{r}
library(readxl)
library(dplyr)

df <- read_excel("Log_Patient_URO_12112015.xlsx")

df1 <- df %>%
  rename(
    Ress_Humaines = `Ress. Humaines`,
    Timestamp_start = `Timestamp start`,
    Timestamp_end   = `Timestamp end`,
    DISTANCE_PARCOURUE = `distance parcourue`
  ) %>%
  mutate(
    Timestamp_start = as.POSIXct(Timestamp_start,
                                 format = "%d/%m/%Y %H:%M:%S",
                                 tz = "Europe/Paris")
  )

temps_systeme <- df1 %>%
  group_by(ID) %>%
  summarise(
    entree = min(Timestamp_start, na.rm = TRUE),
    sortie = max(Timestamp_start,   na.rm = TRUE)
  ) %>%
  ungroup()

events_arr <- temps_systeme %>%
  dplyr::select(time = entree) %>%
  mutate(delta = 1)

events_dep <- temps_systeme %>%
  dplyr::select(time = sortie) %>%
  mutate(delta = -1)

events <- bind_rows(events_arr, events_dep) %>%
  arrange(time)

events <- events %>%
  mutate(
    L_t = cumsum(delta),
    dt = as.numeric(difftime(lead(time), time, units = "hours"))
  )

L <- sum(events$L_t * events$dt, na.rm = TRUE) /
     sum(events$dt, na.rm = TRUE)

L

```

-   Calcul du taux d'arrivée moyen :

```{r}
library(dplyr)
library(readxl)
library(tidyverse)
# Calcul de lamba
# Load the Excel dataset Patient URO
df <- read_excel("Log_Patient_URO_12112015.xlsx")
df

# Rename columns for easier handling
df1 <- df %>%
   rename(Ress_Humaines = `Ress. Humaines`,
        Timestamp_start = `Timestamp start`,
        Timestamp_end   = `Timestamp end`,
        DISTANCE_PARCOURUE = `distance parcourue`)

arrivees <- df1 %>%
  filter(Activity_MACRO == "Entrée des Consultations") %>%
  group_by(ID) %>%
  summarise(arrivee = min(Timestamp_start)) %>%
  ungroup()

arrivees

arrivees_8_18 <- arrivees %>%
  filter(format(arrivee, "%H:%M:%S") >= "08:00:00",
         format(arrivee, "%H:%M:%S") <= "18:00:00")

arrivees_8_18

lambda <- nrow(arrivees_8_18) / 10
lambda
```

-   Calcul du niveau d'attente moyen :

```{r}
# Load the Excel dataset Patient URO
df <- read_excel("Log_Patient_URO_12112015.xlsx")
df

# Rename columns for easier handling
df1 <- df %>%
   rename(Ress_Humaines = `Ress. Humaines`,
        Timestamp_start = `Timestamp start`,
        Timestamp_end   = `Timestamp end`,
        DISTANCE_PARCOURUE = `distance parcourue`)

temps_systeme <- df1 %>%
  group_by(ID) %>%
  summarise(
    entree = min(Timestamp_start, na.rm = TRUE),
    sortie = max(Timestamp_start, na.rm = TRUE)
  ) %>%
  ungroup()

temps_systeme

temps_systeme <- temps_systeme %>%
  mutate(W = as.numeric(difftime(sortie, entree, units = "hours")))

W <- mean(temps_systeme$W, na.rm = TRUE)
W
```

-   Comparaison de $L$ et $\lambda W$ :

    ```{r}
    library(dplyr)
    library(readxl)

    # OCCUPATION
    events <- bind_rows(
      temps_systeme %>% transmute(time = entree, delta = 1),
      temps_systeme %>% transmute(time = sortie, delta = -1)
    ) %>%
      arrange(time) %>%
      mutate(
        L_t = cumsum(delta),
        dt = as.numeric(difftime(lead(time), time, units = "hours"))
      )

    L <- sum(events$L_t * events$dt, na.rm = TRUE) /
         sum(events$dt, na.rm = TRUE)

    L 
    lambda*W
    ```

-   Rappel et conseil : Tenter d'expliquer pourquoi on observe une
    différence. En particulier, pour cette explication penser à pourquoi
    $\lambda W$ peut être assimilée à une moyenne des niveaux de
    présence moyen de patients $m$ :
    $\frac{1}{M}\sum_{m \in M} \frac{1}{t}\int_0^t \mathbb{1}_m(t) dt$
    avec $\mathbb{1}_m(t)$ la fonction d'indicatrice de présence du
    patient $m$

On observe que L≈9 alors que λ\*W≈11 La différence s’explique par le
fait que :

-   L est une moyenne temporelle du nombre de patients présents à chaque
    instant,

-   λ\*W est une moyenne sur les durées de séjour des patients,

-   la journée n’est pas en régime stationnaire (arrivées concentrées le
    matin, départs étalés), et certains patients sont encore présents
    après 18h.\

    Ces effets de bord expliquent que la valeur de LLL soit légèrement
    inférieure à λW\lambda WλW, ce qui est cohérent avec les hypothèses
    de la loi de Little en situation finie.

### Question 2) Processus de Poisson d'arrivée non homogène (/3)

UN processus de poisson est un processus de comptage (dans le temps)
indiquant un nombre évènements ayant occurés entre un temps $0$ et un
temps $t$ selon une distribution de Poisson $\mathcal(P)(\lambda * t)$
avec un taux par unité de temps $\lambda$. Nous verrons dans le cours 3
que les temps entre chaque événement suive une loi de distribution
exponentielle de paramètre $\lambda$.

Un processus de Poisson non homogène (NHPP) est un processus de comptage
où le taux d’événement $\lambda(t)$ n'est pas constant. En considérant
une modélisation de NHPP basé sur taux d'arrivées des tranches [8h;10h],
]10h;12h], ..., ]16h;18h] du service d'urologie générer 30 échantillons
de ce NHPP sur la période 8h, 18h et illustrés les.

Pour vous aider voici un exemple pour un Processus de Poisson homogène :
(n'hésitez pas à aller plus loin aussi pour l'illustration)

```{r}
lambda = 10 # par heure
samples <- tibble(run=to_vec(for(i in 1:10) rep(i,200)),
       id=rep(1:200,10),
       delta_t=rexp(2000,lambda)) %>%
  group_by(run) %>%
  mutate(t = cumsum(delta_t)) %>%
  filter(t <= 10)

# illustration 1
samples %>% 
  ggplot(aes(t,id,color=factor(run))) +
  geom_point() 

# illustration 2
samples %>%   
  mutate(t = cut(t,seq(0,30,by=1),include.lowest = TRUE)) %>%
  count(run,t) %>%
  arrange(run,t) %>%
  ggplot(aes(t,n)) +
  geom_boxplot()
```

```         
Attention : pour un processus de Poisson non homogène, il faudra générer le nombre d'arrivées avec _rpoiss_ pour chaque tranche de temps avec un taux différent et ensuite les répartir uniformément dans le temps (au sein de leur intervalle) en générant des valuers uniform (_runif_).
```

Réponse :

```{r}
#_Entrez votre code R ici_

# Import des données
data_raw <- read_excel("Log_Patient_URO_12112015.xlsx")

# on garde que l'arrivée initiale
data_arrivals <- data_raw %>%
  mutate(arrival_time = ymd_hms(`Timestamp start`)) %>%
  group_by(ID) %>%                
  slice_min(arrival_time, n = 1) %>%        
  ungroup() %>%
  mutate(
    hour = hour(arrival_time) + minute(arrival_time)/60
  ) %>%
  filter(hour >= 8, hour <= 18)

# Découpage en tranches horaires
data_arrivals <- data_arrivals %>%
  mutate(
    tranche = cut(
      hour,
      breaks = c(8,10,12,14,16,18),
      include.lowest = TRUE,
      right = TRUE
    )
  )

# Estimation des taux λ(t)
lambda_hat <- data_arrivals %>%
  count(tranche) %>%
  mutate(lambda = n / 2) 

# Définition des intervalles
intervals <- tibble(
  start  = c(8,10,12,14,16),
  end    = c(10,12,14,16,18),
  lambda = lambda_hat$lambda
)

# Simulation du NHPP (30 runs)
set.seed(123)
n_runs <- 30

samples_nhpp <- map_dfr(1:n_runs, function(run_id) {

  map_dfr(1:nrow(intervals), function(i) {

    dt <- intervals$end[i] - intervals$start[i]
    n_events <- rpois(1, intervals$lambda[i] * dt)

    tibble(
      run = run_id,
      t = runif(n_events, intervals$start[i], intervals$end[i])
    )
  })
}) %>%
  arrange(run, t) %>%
  group_by(run) %>%
  mutate(id = row_number()) %>%
  ungroup()

# Illustration 1 : trajectoires
samples_nhpp %>%
  ggplot(aes(t, id, color = factor(run))) +
  geom_point(alpha = 0.6) +
  labs(
    title = "Processus de Poisson non homogène – Arrivées service d’urologie",
    x = "Temps (heures)",
    y = "Nombre cumulé d’arrivées"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Illustration 2 : arrivées/heure
samples_nhpp %>%
  mutate(hour = cut(t, seq(8,18,by=1), include.lowest = TRUE)) %>%
  count(run, hour) %>%
  ggplot(aes(hour, n)) +
  geom_boxplot() +
  labs(
    title = "Distribution des arrivées par heure (NHPP simulé)",
    x = "Heure",
    y = "Nombre d’arrivées"
  ) +
  theme_minimal()
```

### Question 3) Modélisation de la durée de séjour par une distribution (/3)

A l'aide de la documentation "Ricci-distributions-en.pdf" fournie,
notamment avec la fonction fitdistr() de la librairie MASS, tester la
modélisation (par MLE, *Maximum Likelihood Estimation*) la durée de
séjours de l'ensemble des patients avec différentes distributions :
normale, exponentielle, gamma, weibull.

Réponse :

*Entrez votre texte ici*

```{r}
#_Entrez votre code R ici_

library(readxl)
library(MASS)

data_service <- read_excel("Log_Patient_URO_12112015.xlsx")

data_raw <- data_raw %>%
  mutate(
    datetime_begin = ymd_hms(`Timestamp start`),
    datetime_end   = ymd_hms(`Timestamp end`)
  )

data_patient <- data_raw %>%
  group_by(ID) %>%
  summarise(
    arrival_time = min(datetime_begin, na.rm = TRUE),
    departure_time = max(datetime_end, na.rm = TRUE),
    .groups = "drop"
  )

data_patient <- data_patient %>%
  mutate(
    duree_sejour = as.numeric(difftime(departure_time,
                                       arrival_time,
                                       units = "hours"))
  )

duree <- data_patient$duree_sejour
duree <- duree[!is.na(duree)]
duree <- duree[duree > 0]

summary(duree)
hist(duree, breaks = 30)

fit_norm <- fitdistr(duree, "normal")
fit_norm

fit_exp <- fitdistr(duree, "exponential")
fit_exp

fit_gamma <- fitdistr(duree, "gamma")
fit_gamma

fit_weib <- fitdistr(duree, "weibull")
fit_weib

AIC_fitdistr <- function(fit) {
  k <- length(fit$estimate)
  -2 * fit$loglik + 2 * k
}

AIC_norm  <- AIC_fitdistr(fit_norm)
AIC_exp   <- AIC_fitdistr(fit_exp)
AIC_gamma <- AIC_fitdistr(fit_gamma)
AIC_weib  <- AIC_fitdistr(fit_weib)

AIC_values <- data.frame(
  Distribution = c("Normale", "Exponentielle", "Gamma", "Weibull"),
  AIC = c(AIC_norm, AIC_exp, AIC_gamma, AIC_weib)
)

AIC_values[order(AIC_values$AIC), ]

hist(duree, prob = TRUE, breaks = 30,
     main = "Ajustement des lois – Durée de séjour",
     xlab = "Durée")

curve(dnorm(x,
            mean = fit_norm$estimate[1],
            sd   = fit_norm$estimate[2]),
      add = TRUE, col = "blue", lwd = 2)

curve(dexp(x,
           rate = fit_exp$estimate),
      add = TRUE, col = "red", lwd = 2)

curve(dgamma(x,
             shape = fit_gamma$estimate["shape"],
             rate  = fit_gamma$estimate["rate"]),
      add = TRUE, col = "green", lwd = 2)

curve(dweibull(x,
               shape = fit_weib$estimate["shape"],
               scale = fit_weib$estimate["scale"]),
      add = TRUE, col = "purple", lwd = 2)

legend("topright",
       legend = c("Normale", "Exponentielle", "Gamma", "Weibull"),
       col = c("blue", "red", "green", "purple"),
       lwd = 2)

```

Quelles est la meilleure distribution ? (Justifiez) Comparez aussi les
moyennes, écart-types et coefficients de variation obtenus pour chaque
distribution et par rapport au calcul direct des indicateurs sur les
variables statistiques.

Réponse :

Parmi les distributions étudiées, la loi de Weibull apparaît comme la
plus appropriée pour modéliser la durée de séjour. Elle respecte le
support strictement positif de la variable et reproduit correctement les
principaux indicateurs statistiques, en particulier la variabilité
observée. La loi Gamma aurait également pu constituer un choix
pertinent, car elle présente des caractéristiques proches et un bon
accord avec les données empiriques ; toutefois, la Weibull offre une
flexibilité légèrement supérieure, notamment dans la modélisation des
durées extrêmes et dans l’interprétation du comportement du taux de
sortie au cours du séjour. La loi normale, bien que numériquement
proche, reste conceptuellement inadaptée en raison de son support non
borné inférieur, tandis que la loi exponentielle est clairement
inappropriée car elle impose une variabilité trop élevée par rapport aux
observations. Ainsi, la loi de Weibull est retenue comme meilleur
compromis, la loi Gamma pouvant être considérée comme une alternative
valable en second choix.

```{r}
#_Entrez votre code R ici_

# Indicateurs empiriques
mean_emp <- mean(duree)
sd_emp   <- sd(duree)
cv_emp   <- sd_emp / mean_emp

mean_norm <- fit_norm$estimate["mean"]
sd_norm   <- fit_norm$estimate["sd"]
cv_norm   <- sd_norm / mean_norm

rate_exp <- fit_exp$estimate["rate"]

mean_exp <- 1 / rate_exp
sd_exp   <- 1 / rate_exp
cv_exp   <- sd_exp / mean_exp

shape_g <- fit_gamma$estimate["shape"]
rate_g  <- fit_gamma$estimate["rate"]

mean_gamma <- shape_g / rate_g
sd_gamma   <- sqrt(shape_g) / rate_g
cv_gamma   <- sd_gamma / mean_gamma

shape_w <- fit_weib$estimate["shape"]
scale_w <- fit_weib$estimate["scale"]

mean_weib <- scale_w * gamma(1 + 1 / shape_w)
sd_weib   <- scale_w * sqrt(
  gamma(1 + 2 / shape_w) - gamma(1 + 1 / shape_w)^2
)
cv_weib <- sd_weib / mean_weib

comparaison_table <- data.frame(
  Distribution = c("Empirique", "Normale", "Exponentielle", "Gamma", "Weibull"),
  Moyenne = c(mean_emp, mean_norm, mean_exp, mean_gamma, mean_weib),
  Ecart_type = c(sd_emp, sd_norm, sd_exp, sd_gamma, sd_weib),
  Coefficient_variation = c(cv_emp, cv_norm, cv_exp, cv_gamma, cv_weib)
)

comparaison_table

```

Quel que soit votre réponse, refaites ce travail pour la distribution
gamma en séparant la modélisation des durées de séjour des patients
prioritaires et non prioritaires et comparez les deux distributions
graphiquement et à l'aide leur moments (espérance, variance, coefficient
de variation) et/ou leur paramètres d'échelle et de forme.

Réponse :

L’analyse des durées de séjour des patients selon une loi Gamma montre
que, bien que la durée moyenne soit très proche entre les patients
prioritaires (≈1,76) et non prioritaires (≈1,72), la dispersion diffère
sensiblement. Les patients prioritaires présentent une variance plus
élevée (1,66 contre 0,91) et un coefficient de variation plus important
(0,73 contre 0,55), indiquant une plus grande variabilité relative de
leurs durées de séjour. Cette différence se reflète également dans les
paramètres de la loi Gamma : le paramètre shape des patients
prioritaires (≈1,86) est plus faible que celui des non prioritaires
(≈3,26), ce qui traduit une distribution plus asymétrique et étalée,
avec une queue plus longue à droite. À l’inverse, la distribution des
non prioritaires est plus concentrée autour de la moyenne. Ainsi, même
si les durées moyennes sont similaires, les patients prioritaires
montrent des séjours plus hétérogènes, ce qui peut avoir des
implications pour la planification hospitalière et la gestion des
ressources.

```{r}
#_Entrez votre code R ici_

data_patient <- data_raw %>%
  mutate(
    datetime_begin = ymd_hms(`Timestamp start`),
    datetime_end   = ymd_hms(`Timestamp end`)
  ) %>%
  group_by(ID) %>%
  summarise(
    arrival_time = min(datetime_begin, na.rm = TRUE),
    departure_time = max(datetime_end, na.rm = TRUE),
    prioritaire = ifelse(any(grepl("PRIO", Activity_DETAILS)), "Oui", "Non"),
    .groups = "drop"
  ) %>%
  mutate(
    duree_sejour = as.numeric(difftime(departure_time,
                                       arrival_time,
                                       units = "hours"))
  )

duree_prio <- data_patient %>%
  filter(prioritaire == "Oui") %>%
  pull(duree_sejour)

duree_non_prio <- data_patient %>%
  filter(prioritaire == "Non") %>%
  pull(duree_sejour)

# Nettoyage
duree_prio <- duree_prio[duree_prio > 0 & !is.na(duree_prio)]
duree_non_prio <- duree_non_prio[duree_non_prio > 0 & !is.na(duree_non_prio)]

library(MASS)

fit_gamma_prio <- fitdistr(duree_prio, "gamma")
fit_gamma_non_prio <- fitdistr(duree_non_prio, "gamma")

params_gamma <- data.frame(
  Groupe = c("Prioritaires", "Non prioritaires"),
  Shape = c(fit_gamma_prio$estimate["shape"],
            fit_gamma_non_prio$estimate["shape"]),
  Rate = c(fit_gamma_prio$estimate["rate"],
           fit_gamma_non_prio$estimate["rate"])
)

params_gamma

moments_gamma <- data.frame(
  Groupe = c("Prioritaires", "Non prioritaires"),
  Esperance = c(
    fit_gamma_prio$estimate["shape"] / fit_gamma_prio$estimate["rate"],
    fit_gamma_non_prio$estimate["shape"] / fit_gamma_non_prio$estimate["rate"]
  ),
  Variance = c(
    fit_gamma_prio$estimate["shape"] / fit_gamma_prio$estimate["rate"]^2,
    fit_gamma_non_prio$estimate["shape"] / fit_gamma_non_prio$estimate["rate"]^2
  ),
  Coefficient_variation = c(
    1 / sqrt(fit_gamma_prio$estimate["shape"]),
    1 / sqrt(fit_gamma_non_prio$estimate["shape"])
  )
)

moments_gamma

hist(duree_prio, prob = TRUE, breaks = 30,
     col = rgb(1,0,0,0.35),
     xlim = range(c(duree_prio, duree_non_prio)),
     main = "Comparaison des durées de séjour – Loi Gamma",
     xlab = "Durée (heures)")

curve(dgamma(x,
             shape = fit_gamma_prio$estimate["shape"],
             rate  = fit_gamma_prio$estimate["rate"]),
      col = "red", lwd = 2, add = TRUE)

hist(duree_non_prio, prob = TRUE, breaks = 30,
     col = rgb(0,0,1,0.35),
     add = TRUE)

curve(dgamma(x,
             shape = fit_gamma_non_prio$estimate["shape"],
             rate  = fit_gamma_non_prio$estimate["rate"]),
      col = "blue", lwd = 2, add = TRUE)

legend("topright",
       legend = c("Prioritaires", "Non prioritaires"),
       col = c("red", "blue"),
       lwd = 2)
```

### Question 4) Modélisation de la durée de séjour par régression linéaire (/3)

A l'aide de la fonction *lm*, construisez et analysez un modèle de
régression linéaire estimant la durée de séjour qui prennent en variable
d'entrée le bloc de 2h [8h;10h], ..., ]16h;18h].

Voici un petit exemple d'utilisation :

```{r}
Y = c(1, 1.5, 2, 3)
X = c("A","A","B","B")

model <- lm(Y ~ X)
summary(model) 
predict(model) # predict(model,newdata=[new_dataframe]) if new data
```

Réponse :

*Entrez votre texte ici*

```{r}
library(dplyr)
library(lubridate)

# Crée la variable bloc 2h selon l'heure d'arrivée
temps_systeme <- temps_systeme %>%
  mutate(
    heure_entree = hour(entree),
    bloc_2h = case_when(
      heure_entree >= 8 & heure_entree < 10 ~ "[08h;10h]",
      heure_entree >= 10 & heure_entree < 12 ~ "[10h;12h]",
      heure_entree >= 12 & heure_entree < 14 ~ "[12h;14h]",
      heure_entree >= 14 & heure_entree < 16 ~ "[14h;16h]",
      heure_entree >= 16 & heure_entree < 18 ~ "[16h;18h]",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(bloc_2h))  

temps_systeme

model1 <- lm(W ~ bloc_2h, data = temps_systeme)
summary(model1)

# prédictions sur le même dataset
temps_systeme$pred_W1 <- predict(model1)
```

```{r}
library(ggplot2)

ggplot(temps_systeme, aes(x = bloc_2h, y = W)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.5, color = "blue") +
  geom_point(aes(y = pred_W1), color = "red", size = 3) +
  stat_summary(fun = mean, geom = "point", color = "darkgreen", size = 3) +
  labs(
    title = "Durée de séjour selon le bloc 2h",
    x = "Bloc horaire d'arrivée",
    y = "Durée de séjour W (heures)"
  ) +
  theme_minimal()

```

Refaites un deuxième modèle linéaire intégrant une variable catégorielle
qui indique si le patient est prioritaire.

Réponse :

*Entrez votre texte ici*

```{r}
df1 <- df1 %>%
  mutate(prioritaire = ifelse(grepl("PRIO", Activity_DETAILS), "Oui", "Non"))

temps_systeme2 <- temps_systeme %>%
  dplyr::left_join(
    df1 %>%
      group_by(ID) %>%
      summarise(prioritaire = ifelse(any(grepl("PRIO", Activity_DETAILS)), "Oui", "Non")),
    by = "ID"
  )

df1 %>% filter(grepl("PRIO", Activity_DETAILS))
table(temps_systeme2$prioritaire)
model2 <- lm(W ~ bloc_2h + prioritaire, data = temps_systeme2)
summary(model2)

# prédictions
temps_systeme2$pred_W2 <- predict(model2)
```

```{r}
temps_systeme2 <- temps_systeme2 %>%
  mutate(prioritaire = factor(prioritaire, levels = c("Oui", "Non")))

temps_systeme2
ggplot(temps_systeme2, aes(x = bloc_2h, y = W, color = prioritaire)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.5) +
  geom_point(aes(y = pred_W2), shape = 17, size = 3) +
  labs(
    title = "Durée de séjour selon bloc 2h et priorité",
    x = "Bloc horaire d'arrivée",
    y = "Durée de séjour W (heures)",
    color = "Prioritaire"
  ) +
  theme_minimal()


```

### Question 5) Modélisation de la durée de séjour par un taux de départ (/3)

Une manière alternative de "générer" un temps lié à un évènement est
d'utiliser le taux de défaillance de sa distribution défini par :
$$\mu(t) = \lim_{h \to +\infty} \frac{\mathbb{P}(X<t+h|X>t)}{h} = \lim_{h \to +\infty} \frac{\mathbb{P}(X<t+h) - \mathbb{P}(X<t)}{\mathbb{P}(X>t)h} = \frac{f(t)}{1-F(t)} = \frac{-\frac{dR(t)}{dt}}{R(t)} = -\frac{(ln(R(t))}{dt}$$.

Dans le cas de la loi exponentiel, ce taux est constant car
$\frac{f(t)}{1-F(t)} = \lambda e^{-\lambda t} / (e^{-\lambda t}) = \lambda$,
ce qui est une autre manière de voir que la la loi est sans mémoire.

Dans cette question, il vous est ainsi demandé :

-   Exprimer (sous forme d'équation $\mu(t)=...$), calculer et tracer ce
    taux pour la distribution gamma pour les (3) distributions modéliser
    à la question 3 :

Réponse :

*Entrez votre texte et formules ici*

```{r}
#_Entrez votre code R ici_
```

-   De construire et d'analyser un modèle (calcul de moyennes simples)
    qui estime ce taux de risque par tranche de 30min
    ([0;30min],]30min;60min]...) pour l'ensemble des patients, puis
    séparant selon le bloc d'arrivée de 2h [8h;10h], ..., ]16h;18h],
    puis en séparant par patients prioritaires et non prioritaires

*Entrez votre texte et formules ici*

```{r}
#_Entrez votre code R ici_
```

### Question 6) Calculs des niveaux d'occupation et validation des modèles (/5)

A partir des modèles précédant, il vous est demandé d'estimer, de
visualiser et d'analyser le niveau d'occupation au cours de la journée
en utilisant 30 échantillons de processus d'arrivée de patient (30
journées et pas 30 patients) Il vous est ensuite demandé de comparer la
qualité des estimations des différents modèles à la réalité de manière
visuelle et en utilisant une mesure d'erreur absolu moyenne et/ou
quadratique (ou mis à la $\sqrt()$) et une mesure de biais sur
l'occupation moyenne.

Réponse :

*Entrez votre texte ici*

```{r}
#_Entrez votre code R ici_
```

Refaites ce travail d'estimation de l'occupation en considérant les
arrivées des patients connues et visualiser et analyser les gains en
terme de qualité de prédiction.

Réponse :

*Entrez votre texte ici*

```{r}
#_Entrez votre code R ici_
```

```         
Notes : Ici, on ne sépare pas les données en données d'entraînement et de test pour des raisons pratiques de quantité de données mais c'est un point à tenir en compte dans une vrai validation de modèle.
```

### Question bonus (/1) :

Quelles sont les notations de Kendall des différents modèles de "file
d'attente" que vous avez implémentés ? (Justifiez)

```         
Note :  On est ici sur un cas spécial le modèle de file d'attente est sans file d'attente
```
